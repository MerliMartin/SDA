{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B33tM5JHt8ux",
    "outputId": "e392f202-7d80-4ccb-d26a-d83b0abcfac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPVF2Zo2t8u2"
   },
   "source": [
    "# Example of  a binary classification: classification of movie reviews\n",
    "\n",
    "This is a classification that is divided into two groups (i.e. it is a binary classification). It represents the most common problem of machine learning. By analyzing this example, you will learn to classify movie reviews. You will be able to divide them into positive and negative reviews based on their content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55ZJRhA6t8u5"
   },
   "source": [
    "## The IMDB dataset\n",
    "\n",
    "\n",
    "We'll be working with the IMDB set. It is a collection of 50,000 highly polarized reviews published on the Internet Movie Database. The reviews were divided into a training set (consisting of 25,000 reviews) and a test set (it consists of 25,000 reviews). Each of these collections is made up of half positive and half negative reviews.\n",
    "\n",
    "Why do we use separate collections? In principle you should never test a machine learning model on the same data that was used to train it. Just because the model classifies the training data well does not mean that it will classify it with the same quality level. What we are really interested in is the performance of the model when classifying new data. We know the sample labels of the training dataset. It is obvious that we do not need them. We make predictions by using a model. The model might just remember the training dataset labels and be completely useless when predicting the labels for new reviews. This issue will be described in more detail in the next chapter.\n",
    "\n",
    "The IMDB file, like the MNIST file, is included in the Keras package. This set has already been prepared for analysis: reviews (word sequences) have been converted into sequences of integer values. Each value symbolizes the presence of a selected word from the dictionary in the review.\n",
    "\n",
    "The following code will load a dataset (when you run it for the first time, about 80MB of data will be downloaded to your computer's hard drive).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "RRtr1qVft8u6"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPKrLa1Rt8u7"
   },
   "source": [
    "\n",
    "Num_words = 10000 - this value indicates that only the most common 10,000 words in the training dataset will be retained. Less frequent words will be omitted. This solution allows you to work with a data vector that has a processing size.\n",
    "\n",
    "Train_data and test_data are review lists. Each review is a list of word indexes (as an encoded word sequence). Train_labels and test_labels contain labels in the form of 0s and 1s: 0 is a negative review and 1 is a positive review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7EwyhodXt8u8",
    "outputId": "b75c8c03-2386-4fe5-8186-20c952bfa5bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Sbv0ecvct8u9",
    "outputId": "4ca9f5ab-db66-44b7-ca52-ee31406ef9b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrTFGKu6t8u-"
   },
   "source": [
    "We limit ourselves to the 10,000 most common words. As a result, we will have 10,000 word index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uk1ieu9Xt8u_",
    "outputId": "b184396f-de29-473a-da34-6a6b4c0cb8ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUSZwxvMt8vB"
   },
   "source": [
    "Here's a quick way to decode one of the reviews and read it in English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "9EBDlj31t8vC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# The word_index dictionary assigns index values ​​to words.\n",
    "word_index = imdb.get_word_index ()\n",
    "# By inverting it, we can assign indexes to words.\n",
    "reverse_word_index = dict ([(value, key) for (key, value) in word_index.items ()])\n",
    "# Review the decoded code. Notice that the indexes are shifted by 3 because under the indexes for 0, 1, and 2\n",
    "# there are indexes for \"fill\", \"start of sequence\" and \"unknown word\".\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oAJPfbbQt8vD",
    "outputId": "66fe62ca-686e-4dd1-f192-459456753362",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbeXlcbut8vE"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "\n",
    "An integer list cannot be passed directly to a neural network. You have to turn them into a list of tensors. This can be done in two ways:\n",
    "\n",
    "• You can complete the lists so that they have the same length. Next you can convert them into an integer tensor that has a shape (samples or word_indices). The first layer of the neural network needs to use a layer that can process integer tensors (the Embedding layer - more information on the topic can be found in later chapters).\n",
    "\n",
    "• You can encode lists to convert them into vectors of ones and zeros. This means that you can replace the sequence [3, 5] with a vector of 10,000 dimensions. It  will be filled with all zeros, and only under the indices numbered 3 and 5 there will be ones. In such a situation, the first layer of our network could be a Dense layer that can handle floating point data vectors.\n",
    "\n",
    "\n",
    "Let's use the second solution and convert the data to vectors. For the sake of code clarity, we will do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "id": "NnIMQbSYt8vE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "# Creates a zero padded matrix of the shape (len (sequences), dimension).\n",
    "     results = np.zeros((len (sequences), dimension))\n",
    "     for i, sequence in enumerate (sequences):\n",
    "         results [i, sequence] = 1. # Place the value 1 at the selected indexes.\n",
    "     return results\n",
    "\n",
    "# Training set in the form of a vector.\n",
    "x_train = vectorize_sequences (train_data)\n",
    "# Vector test set.\n",
    "x_test = vectorize_sequences (test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9EgpmzTt8vF"
   },
   "source": [
    "Now samples will look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6ZCuqIlVt8vF",
    "outputId": "f56efbea-a83d-42a5-8378-094c93d79631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJoUAhAUt8vG"
   },
   "source": [
    "We still have to perform the operation of converting sample labels to vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "id": "tfRwGdf0t8vH"
   },
   "outputs": [],
   "source": [
    "# Converting labels to vectors.\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRFgfDQtt8vI"
   },
   "source": [
    "Now the data can be processed by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja_91XXGt8vI"
   },
   "source": [
    "## Construction of a neural network\n",
    "\n",
    "\n",
    "The inputs are vectors and the labels are scalar values ​​(ones and zeros). This is the simplest situation you can deal with. This type of problem is best solved with a simple fully connected layer (Dense) stack network with relu activations: the Dense layer (16, activation = 'relu').\n",
    "\n",
    "The argument passed to each Dense layer (16) is the number of hidden units of the layer. Hidden unit is a dimension of the layer representation space. In Chapter 2, we wrote about how each Dense layer with relu activation implements the following chain of tensor operations:\n",
    "\n",
    "output = relu (dot (W, input) + b)\n",
    "\n",
    "With 16 hidden units, the weight matrix W will have a shape (input_dimension, 16): the dot product of the matrix W will project the input data into a 16-dimensional representation space (then the b threshold vector is added and the relu operation is performed). The dimensions of the data representation space can be understood as \"the degree of freedom that the network has in learning internal data representations\". Increasing the number of hidden units (increasing the number of representation for space dimensions) allows the network to learn more complex representations. The operation of such a network will require more computing power and may lead to the training of unwanted parameters. These are regularities that will improve the processing efficiency of the training dataset but at the same time they are useless when processing test data.\n",
    "When working with Dense layers, you need to answer two questions about the network architecture:\n",
    "\n",
    "• How many layers should be used?\n",
    "\n",
    "• How many hidden units do you need to select in each layer?\n",
    "\n",
    "\n",
    "In the next chapter, we will present the formal rules for answering these questions. For now, let's make the following assumptions:\n",
    "\n",
    "• two intermediate layers - each containing 16 hidden units,\n",
    "\n",
    "• the third layer generating the prediction of the emotional mood of the analyzed review in the form of a scalar value.\n",
    "\n",
    "The mid-tiers will use the relu activation function and the last tier will use the sigmoid activation function. It will generate a value between 0 and 1 indicating the probability that the review is positive. The relu function (a straightened linear unit) is a function to reset negative values ​​(see Figure 3.4), and the sigmoid function \"stuffs\" the values ​​into the range between 0 to 1 (see the Figure 3.5), which allows the network to generate values ​​that can be interpreted as a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXypDnKzt8vJ"
   },
   "source": [
    "The schema of our network:\n",
    "\n",
    "![3-layer network](img\\3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Oqo88Jqt8vM"
   },
   "source": [
    "Here is the network implementation code using the Keras package (it is similar to the network implementation from the MNIST processing example as shown earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "id": "o4yvSBpJt8vM"
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6qq89o3t8vO"
   },
   "source": [
    "\n",
    "Finally, we need to select the loss function and the optimizer. We are working on a binary classification problem and the network returns probability values ​​(at the end of the network there is a layer of one unit with the sigmoid activation function). It is best to use the binary_crossentropy loss function. This is not the only option that we can incorporate. We can also include the mean squared error function mean_squared_error. However, the cross entropy is usually the best option for models that return probability values. The term cross entropy is derived from the information theory. It is a measure of the distance between the probability distributions. In this case this is the distribution of true values ​​and the distribution of predicted values.\n",
    "\n",
    "Below you will find the code setting up the model. In it we select the rmsprop optimizer and the loss function binary_crossentropy. Note that we will also monitor accuracy while training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "id": "01gbWZ99t8vQ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IHUKEXNt8vQ"
   },
   "source": [
    "The metric, optimizer, and loss function are defined using strings. This is possible because rmsprop, binary_crossentropy and accuracy are packages that are part of the Keras library. Sometimes it is necessary to configure optimizer parameters or to pass a self-executed loss function or a metric function. This can be done by passing an instance of the optimizer class as the optimizer argument (see the Listing 3.5) and passing the object function as loss and metrics arguments (see the next block of code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "id": "sjW8W1CAt8vR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\merli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "id": "ek2YX5qYt8vR"
   },
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYF9yangt8vR"
   },
   "source": [
    "## Model validation\n",
    "\n",
    "To monitor the accuracy of the model during training, we will create a dataset that has not been used to train the model. We will do this by detaching 10,000 samples from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "id": "YptbODeit8vT"
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "NNyaRF-ft8vV"
   },
   "source": [
    "In this case we will train the model for 20 epochs (we will perform 20 iterations of all samples located in x_train and y_train tensors) that is divided into batches of 512 samples. At the same time, we will monitor the loss and accuracy functions of the model while processing the 10,000 samples we have just set aside. For this purpose, we need to pass the validation (control) set as the validation_data argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-3MtbPzUt8vV",
    "outputId": "81f25ab3-2b97-4b63-a5bc-1f6125484e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 134ms/step - loss: 0.5330 - binary_accuracy: 0.7861 - val_loss: 0.4018 - val_binary_accuracy: 0.8696\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3247 - binary_accuracy: 0.8997 - val_loss: 0.3230 - val_binary_accuracy: 0.8773\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2348 - binary_accuracy: 0.9257 - val_loss: 0.2896 - val_binary_accuracy: 0.8847\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1867 - binary_accuracy: 0.9383 - val_loss: 0.2889 - val_binary_accuracy: 0.8857\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.1503 - binary_accuracy: 0.9527 - val_loss: 0.2767 - val_binary_accuracy: 0.8895\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.1249 - binary_accuracy: 0.9613 - val_loss: 0.2881 - val_binary_accuracy: 0.8880\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0996 - binary_accuracy: 0.9709 - val_loss: 0.3110 - val_binary_accuracy: 0.8839\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0831 - binary_accuracy: 0.9772 - val_loss: 0.3224 - val_binary_accuracy: 0.8843\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0685 - binary_accuracy: 0.9815 - val_loss: 0.3431 - val_binary_accuracy: 0.8814\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0549 - binary_accuracy: 0.9860 - val_loss: 0.3795 - val_binary_accuracy: 0.8731\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0441 - binary_accuracy: 0.9907 - val_loss: 0.4070 - val_binary_accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0346 - binary_accuracy: 0.9930 - val_loss: 0.4622 - val_binary_accuracy: 0.8646\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0279 - binary_accuracy: 0.9947 - val_loss: 0.4626 - val_binary_accuracy: 0.8756\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.0199 - binary_accuracy: 0.9971 - val_loss: 0.5000 - val_binary_accuracy: 0.8741\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0171 - binary_accuracy: 0.9977 - val_loss: 0.5257 - val_binary_accuracy: 0.8704\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0125 - binary_accuracy: 0.9987 - val_loss: 0.5644 - val_binary_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0079 - binary_accuracy: 0.9993 - val_loss: 0.6606 - val_binary_accuracy: 0.8554\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0073 - binary_accuracy: 0.9994 - val_loss: 0.6320 - val_binary_accuracy: 0.8661\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0059 - binary_accuracy: 0.9993 - val_loss: 0.6639 - val_binary_accuracy: 0.8677\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0031 - binary_accuracy: 0.9999 - val_loss: 0.7036 - val_binary_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKWaRoKst8vV"
   },
   "source": [
    "When training on the CPU, one process epoch takes less than 2 seconds to process. The entire process takes about 20 seconds. At the end of each epoch, the algorithm pauses for a moment as the model calculates the loss and accuracy using 10,000 samples of the validation dataset.\n",
    "\n",
    "Note that by calling model.fit() we return a History object. This object has an item called history, which is a dictionary item of training data. Let's take a look at it in more detail: When training on the CPU, one process epoch takes less than 2 seconds to process. The entire process takes about 20 seconds. At the end of each epoch, the algorithm pauses for a moment as the model calculates the loss and accuracy using 10,000 samples of the validation dataset.\n",
    "\n",
    "Remember, that we called model.fit() that returned a History object. This object had an item called history, which was a dictionary of training data. Let's now take a look at it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yhHrz6hvt8vW",
    "outputId": "87a66d2d-4ea5-476a-fda9-de3eb545582a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d91b6CA6t8vW"
   },
   "source": [
    "The dictionary contains four items: one for each of the metrics monitored during training and validation. Let's create a graph comparing training and validation loss. The second graph we will create changes training accuracy and validation. Your results may be slightly different due to the random network initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FyRIP68Ft8vX",
    "outputId": "156c4753-19d9-4ac8-d6d1-2da98c8945df",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# The bo parameter defines the dashed line in the form of blue dots.\n",
    "plt.plot (epochs, loss, 'bo', label = 'Training loss')\n",
    "# The b parameter defines a solid blue line.\n",
    "plt.plot (epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title ('Training and validation loss')\n",
    "plt.xlabel ('Epochs')\n",
    "plt.ylabel ('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WtePot6ut8vX",
    "outputId": "659475a5-b949-40f5-df50-ed39e953e9fd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwrUlEQVR4nO3deZgU1dn38e/NgCKyyCYi26CiCMFhGQF3cElweUDEBUQjEoOixmhi1EiiPkbfxGgSw+MSMYobEZdEgxE3FlGDKAMCAmIEBAUREQQhyDr3+8epGXqGmpmepadn+X2uq66urq3vqumpu885VafM3RERESmsTroDEBGRqkkJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoQkzcxeMbNLKnrZdDKzFWZ2agq262Z2WDT+FzP7dTLLluFzhpvZ62WNU6Q4pvsgajYz25LwtgGwHdgdvb/c3SdUflRVh5mtAC5z9ykVvF0HOrn70opa1swygU+Beu6+q0ICFSlG3XQHIKnl7g3zxos7GZpZXZ10pKrQ97FqUBVTLWVm/cxslZndaGZfAuPNrKmZ/cvM1pnZN9F424R13jSzy6LxEWb2jpndEy37qZmdXsZlO5rZW2a22cymmNn9ZvZUEXEnE+NvzOzf0fZeN7MWCfMvNrOVZrbezMYUc3z6mNmXZpaRMG2wmS2Ixnub2btmttHM1pjZfWa2TxHbeszM7kh4/4tonS/MbGShZc80sw/M7Fsz+9zMbkuY/Vb0utHMtpjZMXnHNmH9Y81stpltil6PTfbYlPI4NzOz8dE+fGNmLybMG2Rm86J9WGZmA6LpBarzzOy2vL+zmWVGVW0/MrPPgGnR9Oeiv8Om6DvSNWH9/czsD9Hfc1P0HdvPzF42s58U2p8FZjY4bl+laEoQtdtBQDOgAzCK8H0YH71vD3wH3FfM+n2Aj4EWwO+BR8zMyrDs34D3gebAbcDFxXxmMjFeCFwKHAjsA1wPYGZdgAej7R8cfV5bYrj7e8B/gZMLbfdv0fhu4Lpof44BTgGuLCZuohgGRPGcBnQCCrd//Bf4IXAAcCYw2szOjuadGL0e4O4N3f3dQttuBrwMjI327Y/Ay2bWvNA+7HVsYpR0nJ8kVFl2jbb1pyiG3sATwC+ifTgRWFHEZ8Q5CTgS+EH0/hXCcToQmAskVoneA/QCjiV8j28AcoHHgYvyFjKzLKAN4dhIabi7hloyEP5RT43G+wE7gPrFLN8d+Cbh/ZuEKiqAEcDShHkNAAcOKs2yhJPPLqBBwvyngKeS3Ke4GH+V8P5K4NVo/BZgYsK8/aNjcGoR274DeDQab0Q4eXcoYtlrgRcS3jtwWDT+GHBHNP4o8LuE5Q5PXDZmu/cCf4rGM6Nl6ybMHwG8E41fDLxfaP13gRElHZvSHGegNeFE3DRmuYfy4i3u+xe9vy3v75ywb4cUE8MB0TJNCAnsOyArZrn6wDeEdh0IieSBVPxP1fRBJYjabZ27b8t7Y2YNzOyhqMj+LaFK44DEapZCvswbcfet0WjDUi57MLAhYRrA50UFnGSMXyaMb02I6eDEbbv7f4H1RX0WobRwjpntC5wDzHX3lVEch0fVLl9Gcfw/QmmiJAViAFYW2r8+ZjY9qtrZBFyR5Hbztr2y0LSVhF/PeYo6NgWUcJzbEf5m38Ss2g5YlmS8cfKPjZllmNnvomqqb9lTEmkRDfXjPiv6Tj8DXGRmdYBhhBKPlJISRO1W+BK2nwNHAH3cvTF7qjSKqjaqCGuAZmbWIGFau2KWL0+MaxK3HX1m86IWdvfFhBPs6RSsXoJQVbWE8Cu1MXBzWWIglKAS/Q2YBLRz9ybAXxK2W9Ilh18QqoQStQdWJxFXYcUd588Jf7MDYtb7HDi0iG3+l1B6zHNQzDKJ+3ghMIhQDdeEUMrIi+FrYFsxn/U4MJxQ9bfVC1XHSXKUICRRI0KxfWNUn31rqj8w+kWeA9xmZvuY2THA/6QoxueBs8zs+KhB+XZK/h/4G/BTwgnyuUJxfAtsMbPOwOgkY3gWGGFmXaIEVTj+RoRf59ui+vwLE+atI1TtHFLEticDh5vZhWZW18wuALoA/0oytsJxxB5nd19DaBt4IGrMrmdmeQnkEeBSMzvFzOqYWZvo+ADMA4ZGy2cD5yYRw3ZCKa8BoZSWF0Muobruj2Z2cFTaOCYq7RElhFzgD6j0UGZKEJLoXmA/wq+zWcCrlfS5wwkNvesJ9f7PEE4Mce6ljDG6+yLgKsJJfw2hnnpVCas9TWg4nebuXydMv55w8t4MPBzFnEwMr0T7MA1YGr0muhK43cw2E9pMnk1YdytwJ/BvC1dP9S207fXAWYRf/+sJjbZnFYo7WfdS/HG+GNhJKEV9RWiDwd3fJzSC/wnYBMxgT6nm14Rf/N8A/0vBElmcJwgluNXA4iiORNcDHwKzgQ3AXRQ8pz0BdCO0aUkZ6EY5qXLM7BlgibunvAQjNZeZ/RAY5e7HpzuW6kolCEk7MzvazA6NqiQGEOqdX0xzWFKNRdV3VwLj0h1LdaYEIVXBQYRLMLcQruEf7e4fpDUiqbbM7AeE9pq1lFyNJcVQFZOIiMRSCUJERGLVmM76WrRo4ZmZmekOQ0SkWpkzZ87X7t4ybl6NSRCZmZnk5OSkOwwRkWrFzArffZ9PVUwiIhJLCUJERGIpQYiISCwlCBERiaUEISIisVKWIMzsUTP7yswWFjHfzGysmS2NHgfYM2HeJWb2STRckqoYRUSqswkTIDMT6tQJrxMmlLRG6aSyBPEYMKCY+acTHiXYifC4ywch/7GJtxIeUdkbuNXMmqYwThGppsp7gqzO60+YAKNGwcqV4B5eR42q4CSRysfVER7wsbCIeQ8BwxLef0x4lOEw4KGilitq6NWrl4tI9fLUU+4dOribhdennirdug0auIfTYxgaNEh+G9V9/Q4dCq6bN3TokNz6eYAcL+ocXtSMihhKSBD/Ao5PeD8VyCb08Z743NxfA9cXsY1RhIfN5LRv3750R0VEyi2dJ/jyniCr+/pm8eubJbd+nuISRLVupHb3ce6e7e7ZLVvG3ikuIilS3iqOMWNg69aC07ZuDdOT8dlnpZte09ZvX/hhtSVML4t0JojVFHw2b9toWlHTRaSClacOPN0n+PKeIKv7+nfeCQ0aFJzWoEGYXmGKKlpUxEDxVUxnEp5ra0Bf4P1oejPgU6BpNHwKNCvps9QGIVI65a3iKW8VR3mrWNLdBpDu9fO2UdYqvjykow2C8CzfNYTn1q4CfgRcAVwRzTfgfmAZ4bmy2QnrjiQ8r3cpcGkyn6cEIbVReU4Q6a5DrwonyOq+fkVIS4Ko7EEJQmqbdJcAqsIJXsqvuARRrRupRaq7dLYBlLcOfPhwGDcOOnQAs/A6blyYnqzhw2HFCsjNDa+lWVdSTwlCJE3KexVQeRt5K6KRUyf4mk0JQiRNakIJQGo2JQiRNFEJQKo6JQiRcihPG4JKAFLVKUGIlFF52xBUApCqTglCpIzK24agEoBUdRYug63+srOzPScnJ91hSC1Sp04oORRmFn7Ri1QHZjbH3bPj5qkEIbVaOtsQRKo6JQiptapCG4JIVaYEIbWW2hBEiqc2CKm11IYgojYIqcHUhiCSOkoQUm2pDUEktZQgpNpSG4JIaqkNQqottSGIlJ/aIKRGUhuCSGopQUi1pTYEkdRSgpC0Ks9VSGpDEEmtuukOQGqvvKuQ8hqa865CguRP8sOHKyGIpIpKEJI25b0KSURSSwlC0qa8T1QTkdRSgpC00VVIIlWbEoSkja5CEqnalCAkbXQVkkjVpquYJK10FZJI1aUShIiIxFKCkHIpz41uIlK1qYpJyqwibnQTkapLJQgpM93oJlKzKUFImelGN5GaTQlCykw3uonUbEoQUma60U2kZlOCkDLTjW4iNZuuYpJy0Y1uIjWXShC1nO5jEJGiqARRi+k+BhEpTkpLEGY2wMw+NrOlZnZTzPwOZjbVzBaY2Ztm1jZh3m4zmxcNk1IZZ22l+xhEpDgpK0GYWQZwP3AasAqYbWaT3H1xwmL3AE+4++NmdjLwW+DiaN537t49VfGJ7mMQkeKlsgTRG1jq7svdfQcwERhUaJkuwLRofHrMfEkh3ccgIsVJZYJoA3ye8H5VNC3RfOCcaHww0MjMmkfv65tZjpnNMrOz4z7AzEZFy+SsW7euAkOvHXQfg4gUJ91XMV0PnGRmHwAnAauB3dG8Du6eDVwI3GtmhxZe2d3HuXu2u2e3bNmy0oKuKXQfg4gUJ5VXMa0G2iW8bxtNy+fuXxCVIMysITDE3TdG81ZHr8vN7E2gB7AshfHWSrqPQUSKksoSxGygk5l1NLN9gKFAgauRzKyFmeXF8Evg0Wh6UzPbN28Z4DggsXFbRERSLGUJwt13AVcDrwEfAc+6+yIzu93MBkaL9QM+NrP/AK2AvNrvI4EcM5tPaLz+XaGrn0REJMXM3dMdQ4XIzs72nJycdIchIlKtmNmcqL13L+lupBYRkSpKCUJERGIpQVRz6mxPRFJFnfVVY+psT0RSSSWIakyd7YlIKilBVGPqbE9EUkkJohpTZ3sikkpKENWYOtsTkVRSgqjG1NmeiKSSrmKq5tTZnoikikoQIiISSwlCRERiKUGIiEgsJQgREYmlBJFm6ktJRKoqXcWURupLSUSqMpUg0kh9KYlIVaYEkUbqS0lEqjIliDRSX0oiUpUpQaSR+lISkapMCSKN1JeSiFRluoopzdSXkohUVSpBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEiulCcLMBpjZx2a21MxuipnfwcymmtkCM3vTzNomzLvEzD6JhktSGaeIiOwtZQnCzDKA+4HTgS7AMDPrUmixe4An3P0o4Hbgt9G6zYBbgT5Ab+BWM2uaqljLY8IEyMyEOnXC64QJ6Y5IRKRiJJUgzGx/M6sTjR9uZgPNrF4Jq/UGlrr7cnffAUwEBhVapgswLRqfnjD/B8Ab7r7B3b8B3gAGJBNrZZowAUaNgpUrwT28jhqlJCEiNUOyJYi3gPpm1gZ4HbgYeKyEddoAnye8XxVNSzQfOCcaHww0MrPmSa6bdmPGwNatBadt3Rqmi4hUd8kmCHP3rYST+QPufh7QtQI+/3rgJDP7ADgJWA3sTnZlMxtlZjlmlrNu3boKCKd0PvusdNNFRKqTpBOEmR0DDAdejqZllLDOaqBdwvu20bR87v6Fu5/j7j2AMdG0jcmsGy07zt2z3T27ZcuWSe5KxWnfvnTTRUSqk2QTxLXAL4EX3H2RmR1CaDMozmygk5l1NLN9gKHApMQFzKxFXttGtP1Ho/HXgO+bWdOocfr70bQq5c47oUGDgtMaNAjTRUSqu7rJLOTuM4AZANEJ/Wt3v6aEdXaZ2dWEE3sG8GiUXG4Hctx9EtAP+K2ZOaGd46po3Q1m9htCkgG43d03lHrvUmz48PA6ZkyoVmrfPiSHvOkiItWZuXvJC5n9DbiC0D4wG2gM/Nnd705teMnLzs72nJycdIchIlKtmNkcd8+Om5dsFVMXd/8WOBt4BehIuJJJRERqqGQTRL3ovoezgUnuvhMoueghIiLVVrIJ4iFgBbA/8JaZdQC+TVVQIiKSfsk2Uo8FxiZMWmlm/VMTklSWHTvggw8gJwfq1oUDDyw4NG4MZumOUkTSJakEYWZNCH0jnRhNmkHoO2lTiuKSCuYOn38Os2btGebOhe3bi15n3333ThoHHgitWu09rXXr0B+ViNQcSSUIwv0JC4Hzo/cXA+PZ002GVDFbt8KcOXuSwbvvwpo1YV79+pCdDT/5CfTtC717Q0YGfPUVrF0bXuOGhQvDa1xSad4cjjsOTjgBjj8eevaEffap3H0WkYqVbII41N2HJLz/XzObl4J4pAzcYdmygslg/nzYHXVacuihcPLJIRn07QtZWVAvpqvFgw9O7rM2by6YONasgdmz4Z13YFJ0K+R++0GfPiFhnHBC+NxGjSpun0Uk9ZJNEN+Z2fHu/g6AmR0HfJe6sGqXXbtg40bYtCkM3367Z7zw+7h533wDW7aEbTVsGEoEN94IxxwTTtIV2QuJWWibaNwYDjtsz/TRo8Prl1+GRPHOO/D22+HGwdzcUELp3j2ULvJKGa1aVVxcIlLxkr1RLgt4AmgSTfoGuMTdF6QwtlKpjjfKLVkC990Hjz++5wRflPr1w0m5SZOCQ960rl3Dr/QuXcLJuKrYvDmUaPISxqxZsG1bmNep055k0bx5aDQvbti5s+h5rVuHY9C1azgGjRund79FqovibpRLKkEkbKgxgLt/a2bXuvu9FRNi+VWXBLF7N7zyCowdC2+8EerpL7ggtAnEnfjzhppSn79jR2gcf/vtPSWNDUl2opKREY5DvXrhNW+oWxdWr4bvEsq0bdvuSRiJiUPVXCIFVViCKLTRz9y9yvRbWtUTxMaN8OijcP/9sHw5tGkTqmV+/ONwFVBtlZsL//lPOLkXPvEnDvXqFV8y2r0bVqyARYv2DIsXw0cf7SmxQOgvq0uXvRNHw4Yp31WRKqm4BJFsG0Tsdsuxbq2xeDH83//BE0+EK4uOPx5++1sYPDi+obi2qVMHOncu/3YyMkJj/KGHwsCBe6bv3g2fflowcSxaBNOnF7wa65RT4OaboX9/3fshkqc8CUJdbRRh9274179CYpg6NdxPMHw4XH019OiR7uhql4yM0Jh+2GEwKOGBt7t3h5LcokWhyuvhh0OS6Ns39M575plKFCLFVjGZ2WbiE4EB+7l7eRJMhaoKVUwbNsAjj8ADD4TqjrZt4aqr4LLLoEWLtIYmJdi2DcaPh7vuCs8WP+qoUKI499yq1egvUtHK3Juruzdy98YxQ6OqlBzS7cMPYdSokBBuuCHUcz//fKjauOkmJYfqoH790Cb0ySfhqrIdO2Do0NA+MX58eC9S26hzhDLKzQ1XI512Wvi1+eSToRpp3jyYMQOGDAlX10j1Uq8e/PCH4a7x55+H/feHkSNDFdV99xW8UkqkpivzVUxVTWVVMX33HTz1FPzpT+EKmYMPDm0Lo0aFa/mlZnGHV18NN/z9+9/hirOf/SyUNmrCvRbbt4e2ss8/j+9j68ADdYVXTZeSy1yrmlQniC+/DG0LDz4IX38dGpt/9jM4//yac4+CFO+tt0KieP11OOAAuOaaMFTXHwZvvx0us/7443B/yObN8cs1aBCfOBI7buzUKVStqmG/+lGCKIcPPwylhQkTwp28//M/ITGceKL+GWqr2bPDpcovvBCqoK64As44A5o2hWbNwtCwYdX9fmzcGLpiGTcOMjPDj54BA0JD/bp1BfvZKq7zxp07C263VavQzUufPuH16KNDIpWqTQmilHJz4bXX4I9/hClTwi+oESPgpz+Fww+vkI+QGmDRIvjd7+Dpp/d0jJinbt09CSMxcRR+nzferVvqq3Lc4e9/D734fvUVXHcd/O//hiRXlm1t3LgniSxcCO+9B++/H7qQydO5856k0adP2E+VuKsWJYgkxbUv/OQnoX2hWbMKClRqnNWrQ2+6GzaE4Ztv9ozHvd8U8xSVxo3Dj5Arr4Qjjqj4GD//PLSVTZoUqkf/+tfQJXsqbNwYSll5CeO990IigXBPUM+ee0oZffpAx45Vt7RVGyhBlEDtC1KZdu0KSSIvYXz1FTzzDDz7bKi2+f73w8n8jDPKfw/G7t3he/3LX4bx3/wmlIQr8wo793BvSV6yeO+98KySvC5QWrSADh2K7mYlrv+twsPJJ+sm1LJSgijG0qWhPx61L0i6rV0b7uj+y19CqSQzM1wt9aMfla0hPO/+nFmzQtL5y1/Cr/WqYOfOgtVSa9eWrvfeHTsKVuvts084dj/8Yfr2qbpSgiiGe6hHHjJE7QtSNezcGaqC7rsP3nwz3MQ3bFgoVSRTLbRtWygp/P73oZH43nvhwgtr3o+e3bvDsfrmG7joIpg2LZSU7rij6j/+NjcX1q8PtRdr14b9KNyDc8OGlbMfShAi1dTChaEH4LzOHo85JiSKc8+Nr/6cPh0uvzzcEX7JJXDPPbXjTv6dO8NxGTcOzjkn3LjaoEHlxpDXcP/ll3tO/ImvieNffbX3hQ2FmYXLj4t6Bkzi0L59qAEpCyUIkWpu48bQBcj994eTf6tWofro8stD1/EbNsAvfhG6lD/kEHjoITj11HRHXbncQ2np5z8PJa1Jk5J7jG55fPFFuGR4xow91WSF1asX/l4HHbTntfB4vXrxT4ws6QmTeT0S9+0bHsxVFkoQIjVEbm540NR998HLL4cqiLPOCieH9evh+uvhllsq/9dzVfKvf4UquSZNQpJIxdVau3eHC1vGjAlJYciQ0Bdb3Mm/adPUVe9t3x4Sxa5dZU+GShAiNdDy5eEKpfHjQ19RDz0EWVnpjqpqWLAgVLl8/XW4dH3w4Irbdk5OuDlyzpzQF9sDDxR8Pnt1U+beXEWk6jrkELj77nASnDVLySHRUUeFq6O6dQttEnfdFaqgymPTpnBfVO/e4SqziRPDDbXVOTmURAlCRGqkVq1Co/3QoaHb/UsvLfgUwWS5h/tUOncObUBXXRXuFr/ggpp3ZVhh6pBaRGqs/faDv/0tnNxvuy1Uy/3jH8lf2bVsWUgIr70W2jJeegmyYytjaiaVIESkRjODW28NfWa9/37o3uOjj4pfZ/v2cD/F974HM2fC2LFh3dqUHEAJQkRqiaFDw42H//1vuJ/kjTfil5s+PbTn/PrXMHBgqE76yU9q56NnlSBEpNbo2zd079G+PZx+ergKLM9XX4WbC08+Odx498oroe0h1fdSVGVqgxCRWqVDh/B0wGHDQu+5H30Urna68UbYsgV+9Su4+ebQflHbKUGISK3TqBH8859www3huS8A/fqFexqOPDKtoVUpShAiUitlZMAf/hDua3CvHZetlpYShIjUahdckO4Iqq6UNlKb2QAz+9jMlprZTTHz25vZdDP7wMwWmNkZ0fRMM/vOzOZFw19SGaeIiOwtZSUIM8sA7gdOA1YBs81skrsvTljsV8Cz7v6gmXUBJgOZ0bxl7t49VfGJiEjxUlmC6A0sdffl7r4DmAgMKrSMA42j8SbAFymMR0RESiGVCaIN8HnC+1XRtES3AReZ2SpC6eEnCfM6RlVPM8zshLgPMLNRZpZjZjnr1q2rwNBFRCTdN8oNAx5z97bAGcCTZlYHWAO0d/cewM+Av5lZ48Iru/s4d8929+yWLVtWauAiIjVdKhPEaqBdwvu20bREPwKeBXD3d4H6QAt33+7u66Ppc4BlgJ4YLSJSiVKZIGYDncyso5ntAwwFJhVa5jPgFAAzO5KQINaZWcuokRszOwToBCxPYawiIlJIyq5icvddZnY18BqQATzq7ovM7HYgx90nAT8HHjaz6wgN1iPc3c3sROB2M9sJ5AJXuPuGVMUqIiJ70yNHRURqMT1yVERESk0JQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEqtuugMQkYq3c+dOVq1axbZt29IdilQR9evXp23bttSrVy/pdZQgRGqgVatW0ahRIzIzMzGzdIcjaeburF+/nlWrVtGxY8ek11MVk0gNtG3bNpo3b67kIACYGc2bNy91iVIJQqSGUnKQRGX5PihBiIhILCUIEWHCBMjMhDp1wuuECeXb3vr16+nevTvdu3fnoIMOok2bNvnvd+zYUey6OTk5XHPNNSV+xrHHHlu+IAu59tpradOmDbm5uRW63epMjdQitdyECTBqFGzdGt6vXBneAwwfXrZtNm/enHnz5gFw22230bBhQ66//vr8+bt27aJu3fjTT3Z2NtnZ2SV+xsyZM8sWXIzc3FxeeOEF2rVrx4wZM+jfv3+FbTtRcftdFakEIVLLjRmzJznk2bo1TK9II0aM4IorrqBPnz7ccMMNvP/++xxzzDH06NGDY489lo8//hiAN998k7POOgsIyWXkyJH069ePQw45hLFjx+Zvr2HDhvnL9+vXj3PPPZfOnTszfPhw3B2AyZMn07lzZ3r16sU111yTv93C3nzzTbp27cro0aN5+umn86evXbuWwYMHk5WVRVZWVn5SeuKJJzjqqKPIysri4osvzt+/559/Pja+E044gYEDB9KlSxcAzj77bHr16kXXrl0ZN25c/jqvvvoqPXv2JCsri1NOOYXc3Fw6derEunXrgJDIDjvssPz3qVZ9UpmIpMRnn5VuenmsWrWKmTNnkpGRwbfffsvbb79N3bp1mTJlCjfffDN///vf91pnyZIlTJ8+nc2bN3PEEUcwevTova7l/+CDD1i0aBEHH3wwxx13HP/+97/Jzs7m8ssv56233qJjx44MGzasyLiefvpphg0bxqBBg7j55pvZuXMn9erV45prruGkk07ihRdeYPfu3WzZsoVFixZxxx13MHPmTFq0aMGGDRtK3O+5c+eycOHC/EtMH330UZo1a8Z3333H0UcfzZAhQ8jNzeXHP/5xfrwbNmygTp06XHTRRUyYMIFrr72WKVOmkJWVRcuWLUt55MtGJQiRWq59+9JNL4/zzjuPjIwMADZt2sR5553H9773Pa677joWLVoUu86ZZ57JvvvuS4sWLTjwwANZu3btXsv07t2btm3bUqdOHbp3786KFStYsmQJhxxySP5JuagEsWPHDiZPnszZZ59N48aN6dOnD6+99hoA06ZNY/To0QBkZGTQpEkTpk2bxnnnnUeLFi0AaNasWYn73bt37wL3H4wdO5asrCz69u3L559/zieffMKsWbM48cQT85fL2+7IkSN54okngJBYLr300hI/r6IoQYjUcnfeCQ0aFJzWoEGYXtH233///PFf//rX9O/fn4ULF/LSSy8VeY3+vvvumz+ekZHBrl27yrRMUV577TU2btxIt27dyMzM5J133ilQzZSsunXr5jdw5+bmFmiMT9zvN998kylTpvDuu+8yf/58evToUez9Ce3ataNVq1ZMmzaN999/n9NPP73UsZWVEoRILTd8OIwbBx06gFl4HTeu7A3Uydq0aRNt2rQB4LHHHqvw7R9xxBEsX76cFStWAPDMM8/ELvf000/z17/+lRUrVrBixQo+/fRT3njjDbZu3copp5zCgw8+CMDu3bvZtGkTJ598Ms899xzr168HyK9iyszMZM6cOQBMmjSJnTt3xn7epk2baNq0KQ0aNGDJkiXMmjULgL59+/LWW2/x6aefFtguwGWXXcZFF11UoARWGVKaIMxsgJl9bGZLzeymmPntzWy6mX1gZgvM7IyEeb+M1vvYzH6QyjhFarvhw2HFCsjNDa+pTg4AN9xwA7/85S/p0aNHqX7xJ2u//fbjgQceYMCAAfTq1YtGjRrRpEmTAsts3bqVV199lTPPPDN/2v7778/xxx/PSy+9xJ///GemT59Ot27d6NWrF4sXL6Zr166MGTOGk046iaysLH72s58B8OMf/5gZM2aQlZXFu+++W6DUkGjAgAHs2rWLI488kptuuom+ffsC0LJlS8aNG8c555xDVlYWF1xwQf46AwcOZMuWLZVavQRgea39Fb5hswzgP8BpwCpgNjDM3RcnLDMO+MDdHzSzLsBkd8+Mxp8GegMHA1OAw919d1Gfl52d7Tk5OSnZF5Hq5qOPPuLII49Mdxhpt2XLFho2bIi7c9VVV9GpUyeuu+66dIdVajk5OVx33XW8/fbb5dpO3PfCzOa4e+x1xaksQfQGlrr7cnffAUwEBhVaxoHG0XgT4ItofBAw0d23u/unwNJoeyIiSXv44Yfp3r07Xbt2ZdOmTVx++eXpDqnUfve73zFkyBB++9vfVvpnp7IEcS4wwN0vi95fDPRx96sTlmkNvA40BfYHTnX3OWZ2HzDL3Z+KlnsEeMXdny/0GaOAUQDt27fvtXLlypTsi0h1oxKExKlKJYhkDAMec/e2wBnAk2aWdEzuPs7ds909u7KuCxYRqS1SeaPcaqBdwvu20bREPwIGALj7u2ZWH2iR5LoiIpJCqSxBzAY6mVlHM9sHGApMKrTMZ8ApAGZ2JFAfWBctN9TM9jWzjkAn4P0UxioiIoWkrATh7rvM7GrgNSADeNTdF5nZ7UCOu08Cfg48bGbXERqsR3hoFFlkZs8Ci4FdwFXFXcEkIiIVL6VtEO4+2d0Pd/dD3f3OaNotUXLA3Re7+3HunuXu3d399YR174zWO8LdX0llnCJSsfr375/fXUWee++9N7/bijj9+vUj71L1M844g40bN+61zG233cY999xT7Ge/+OKLLF6cfzU9t9xyC1OmTClF9JIn3Y3UIlIDDRs2jIkTJxaYNnHixGI7zEs0efJkDjjggDJ9duEEcfvtt3PqqaeWaVvpsnt31agwUYIQqeGuvRb69avY4dpri//Mc889l5dffjm/P6IVK1bwxRdfcMIJJzB69Giys7Pp2rUrt956a+z6mZmZfP311wDceeedHH744Rx//PH5XYJDuMfh6KOPJisriyFDhrB161ZmzpzJpEmT+MUvfkH37t1ZtmxZgW64p06dSo8ePejWrRsjR45k+/bt+Z9366230rNnT7p168aSJUv2imnFihWccMIJ9OzZk549exZ4HsVdd91Ft27dyMrK4qabQqcRS5cu5dRTTyUrK4uePXuybNmyAl2ZA1x99dX53YxkZmZy44030rNnT5577rnY/YP4LshvueUW7r333vztjhkzhj//+c/F/5GSoAQhIhWuWbNm9O7dm1deCbXDEydO5Pzzz8fMuPPOO8nJyWHBggXMmDGDBQsWFLmdOXPmMHHiRObNm8fkyZOZPXt2/rxzzjmH2bNnM3/+fI488kgeeeQRjj32WAYOHMjdd9/NvHnzOPTQQ/OX37ZtGyNGjOCZZ57hww8/ZNeuXfn9LAG0aNGCuXPnMnr06NhqrAMPPJA33niDuXPn8swzz+Q/9e6VV17hn//8J++99x7z58/nhhtuAGD48OFcddVVzJ8/n5kzZ9K6desSj1vz5s2ZO3cuQ4cOjd0/IL8L8vnz5zN37ly6du1aoMfX3NxcJk6cyEUXXVTi55VEz4MQqeESflhWqrxqpkGDBjFx4sT8E9yzzz7LuHHj2LVrF2vWrGHx4sUcddRRsdt4++23GTx4MA2i7mYHDhyYP2/hwoX86le/YuPGjWzZsoUf/KD4Lts+/vhjOnbsyOGHHw7AJZdcwv3338+1UXHonHPOAaBXr1784x//2Gv9nTt3cvXVVzNv3jwyMjL4z3/+A8CUKVO49NJL82Ns1qwZmzdvZvXq1QwePBiA+vXrJ3XMEvtfKmr/pk2blp8M8rogb9KkCc2bN+eDDz5g7dq19OjRg+bNmyf1mcWp9SWIin4Wr4gEgwYNYurUqcydO5etW7fSq1cvPv30U+655x6mTp3KggULOPPMM4vt6ro4I0aM4L777uPDDz/k1ltvLfN28uR1GV5Ud+F/+tOfaNWqFfPnzycnJ6fEZ2vHSewSHNgr5sQO/kq7f5dddhmPPfYY48ePZ+TIkaWOLU6tThB5z+JduRLc9zyLV0lCpPwaNmxI//79GTlyZH7j9Lfffsv+++9PkyZNWLt2bX4VVFFOPPFEXnzxRb777js2b97MSy+9lD9v8+bNtG7dmp07dzIh4Z+2UaNGbN68ea9tHXHEEaxYsYKlS5cC8OSTT3LSSSclvT+bNm2idevW1KlThyeffDK/Ifm0005j/Pjx+W0EGzZsoFGjRrRt25YXX3wRgO3bt7N161Y6dOjA4sWL2b59Oxs3bmTq1KlFfl5R+xfXBTnA4MGDefXVV5k9e3aJpalk1eoEUVnP4hWprYYNG8b8+fPzE0RWVhY9evSgc+fOXHjhhRx33HHFrt+zZ08uuOACsrKyOP300zn66KPz5/3mN7+hT58+HHfccXTu3Dl/+tChQ7n77rvp0aMHy5Yty59ev359xo8fz3nnnUe3bt2oU6cOV1xxRdL7cuWVV/L444+TlZXFkiVL8n/tDxgwgIEDB5KdnU337t3z2y+efPJJxo4dy1FHHcWxxx7Ll19+Sbt27Tj//PP53ve+x/nnn0+PHj2K/Lyi9i+uC3KAffbZh/79+3P++edX2DMjUtZZX2UrS3ffdeqEkkNhZqFffJHqSp311T65ubn5V0B16tQpdpnq1llfWlXms3hFRFJl8eLFHHbYYZxyyilFJoeyqNVXMd15Z2hzSKxmStWzeEVEUqVLly4sX768wrdbq0sQ6XoWr0hlqCnVx1IxyvJ9qNUlCAjJQAlBapr69euzfv16mjdvjpmlOxxJM3dn/fr1Sd+PkafWJwiRmqht27asWrWKdevWpTsUqSLq169P27ZtS7WOEoRIDVSvXj06duyY7jCkmqvVbRAiIlI0JQgREYmlBCEiIrFqzJ3UZrYOWJnuOIrRAvg63UEUQ/GVj+IrH8VXPuWJr4O7t4ybUWMSRFVnZjlF3c5eFSi+8lF85aP4yidV8amKSUREYilBiIhILCWIyjMu3QGUQPGVj+IrH8VXPimJT20QIiISSyUIERGJpQQhIiKxlCAqiJm1M7PpZrbYzBaZ2U9jlulnZpvMbF403JKGOFeY2YfR5+/1CD4LxprZUjNbYGY9KzG2IxKOzTwz+9bMri20TKUeQzN71My+MrOFCdOamdkbZvZJ9Nq0iHUviZb5xMwuqcT47jazJdHf7wUzO6CIdYv9LqQwvtvMbHXC3/CMItYdYGYfR9/FmyoxvmcSYlthZvOKWLcyjl/seaXSvoPurqECBqA10DMabwT8B+hSaJl+wL/SHOcKoEUx888AXgEM6Au8l6Y4M4AvCTfxpO0YAicCPYGFCdN+D9wUjd8E3BWzXjNgefTaNBpvWknxfR+oG43fFRdfMt+FFMZ3G3B9En//ZcAhwD7A/ML/T6mKr9D8PwC3pPH4xZ5XKus7qBJEBXH3Ne4+NxrfDHwEtElvVGUyCHjCg1nAAWbWOg1xnAIsc/e03h3v7m8BGwpNHgQ8Ho0/Dpwds+oPgDfcfYO7fwO8AQyojPjc/XV33xW9nQWUro/nClTE8UtGb2Cpuy939x3ARMJxr1DFxWfhQRrnA09X9Ocmq5jzSqV8B5UgUsDMMoEewHsxs48xs/lm9oqZda3cyABw4HUzm2Nmo2LmtwE+T3i/ivQkuqEU/Y+Z7mPYyt3XRONfAq1ilqkqx3EkoUQYp6TvQipdHVWBPVpE9UhVOH4nAGvd/ZMi5lfq8St0XqmU76ASRAUzs4bA34Fr3f3bQrPnEqpMsoD/A16s5PAAjnf3nsDpwFVmdmIaYiiWme0DDASei5ldFY5hPg9l+Sp5rbiZjQF2AROKWCRd34UHgUOB7sAaQjVOVTSM4ksPlXb8ijuvpPI7qARRgcysHuGPOMHd/1F4vrt/6+5bovHJQD0za1GZMbr76uj1K+AFQlE+0WqgXcL7ttG0ynQ6MNfd1xaeURWOIbA2r9otev0qZpm0HkczGwGcBQyPTiB7SeK7kBLuvtbdd7t7LvBwEZ+b7uNXFzgHeKaoZSrr+BVxXqmU76ASRAWJ6isfAT5y9z8WscxB0XKYWW/C8V9fiTHub2aN8sYJjZkLCy02CfihBX2BTQlF2cpS5C+3dB/DyCQg74qQS4B/xizzGvB9M2saVaF8P5qWcmY2ALgBGOjuW4tYJpnvQqriS2zTGlzE584GOplZx6hEOZRw3CvLqcASd18VN7Oyjl8x55XK+Q6msgW+Ng3A8YRi3gJgXjScAVwBXBEtczWwiHBFxizg2EqO8ZDos+dHcYyJpifGaMD9hCtIPgSyKznG/Qkn/CYJ09J2DAmJag2wk1CH+yOgOTAV+ASYAjSLls0G/pqw7khgaTRcWonxLSXUPed9D/8SLXswMLm470Ilxfdk9N1aQDjRtS4cX/T+DMJVO8sqM75o+mN537mEZdNx/Io6r1TKd1BdbYiISCxVMYmISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQKYGZ7baCvcxWWM+iZpaZ2JOoSFVSN90BiFQD37l793QHIVLZVIIQKaPoeQC/j54J8L6ZHRZNzzSzaVFndFPNrH00vZWF5zPMj4Zjo01lmNnDUX//r5vZftHy10TPAVhgZhPTtJtSiylBiJRsv0JVTBckzNvk7t2A+4B7o2n/Bzzu7kcROsobG00fC8zw0NFgT8IduACdgPvdvSuwERgSTb8J6BFt54rU7JpI0XQntUgJzGyLuzeMmb4CONndl0cdqn3p7s3N7GtC9xE7o+lr3L2Fma0D2rr79oRtZBL67O8Uvb8RqOfud5jZq8AWQo+1L3rUSaFIZVEJQqR8vIjx0tieML6bPW2DZxL6xeoJzI56GBWpNEoQIuVzQcLru9H4TELvowDDgbej8anAaAAzyzCzJkVt1MzqAO3cfTpwI9AE2KsUI5JK+kUiUrL9rOCD619197xLXZua2QJCKWBYNO0nwHgz+wWwDrg0mv5TYJyZ/YhQUhhN6Ek0TgbwVJREDBjr7hsraH9EkqI2CJEyitogst3963THIpIKqmISEZFYKkGIiEgslSBERCSWEoSIiMRSghARkVhKECIiEksJQkREYv1/kSpUCZM+uW4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # The cleaning draw.\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot (epochs, acc, 'bo', label = 'Training Accuracy')\n",
    "plt.plot (epochs, val_acc, 'b', label = 'Validation accuracy')\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.xlabel ('Epochs')\n",
    "plt.ylabel ('Loss')\n",
    "plt.legend ()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE2m7xvlt8vY"
   },
   "source": [
    "As you can see, the training loss decreases with each epoch while the accuracy of training increases. This is what we expect from the optimization with the gradient descent algorithm. The value that we are trying to minimize should decrease with each subsequent iteration. In the fourth epoch the validation loss and validation accuracy increase. This is an example of a situation we took notice of  earlier. A model that works better on a training dataset does not have to work better when processing new data. In practice, this is an example of overfitting - after the second epoch, the model is too optimized on the training dataset and learns a specific representation of the training dataset. It does not take into account the overall vision that works well beyond the training dataset.\n",
    "\n",
    "In this case, we can prevent overfitting by breaking the algorithm after 3 epochs. We can use many techniques to prevent overfitting of the model. We will focus on them in the next chapter.\n",
    "\n",
    "Now we can train the new network from scratch (let's do it over four epochs) and then evaluate it against a test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QmjC32rAt8vZ",
    "outputId": "cd05342b-10f5-4388-e1ed-cb3b434a7172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 2s 17ms/step - loss: 0.4468 - accuracy: 0.8148\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.2563 - accuracy: 0.9114\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1988 - accuracy: 0.9287\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1631 - accuracy: 0.9432\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3822 - accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wS4lJAzyt8vZ",
    "outputId": "07bcaeb0-2dff-4119-85fd-57b99c08a438",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38218024373054504, 0.8533599972724915]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDyrvlx1t8va"
   },
   "source": [
    "[link text](https://) This naive solution helps obtain an accuracy of 88%. Refined models should approach 95% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGeU1hEpt8va"
   },
   "source": [
    "## Using a trained network to generate predictions about new data\n",
    "\n",
    "Once the net is trained, we can use it to do something practical. To generate a value that determines the probability that a review is positive we can  use the predict method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YqYTvYRet8vd",
    "outputId": "9e8631c8-83b1-44ec-aedd-d7f2b6fda26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09140945],\n",
       "       [0.99919325],\n",
       "       [0.2858565 ],\n",
       "       ...,\n",
       "       [0.04580709],\n",
       "       [0.03081057],\n",
       "       [0.31643167]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXHVEtc4t8vd"
   },
   "source": [
    "For new samples, the network is very confident in its verdict (it produces values ​​close to 0.99 or 0.01). For others it produces much less reliable results, such as 0.6 or 0.4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NJL-fG4t8ve"
   },
   "source": [
    "## Further experiments\n",
    "\n",
    "Here are the experiments that will help you confirm that we have chosen a  reasonable architecture (they can also be improved):\n",
    "\n",
    "* We used two hidden layers. Try adding one or three hidden layers and see how this affects the accuracy of the validation and the testing.\n",
    "* Try to use layers with more or less hidden units: try layers with e.g. 32 and 64 units.\n",
    "* Use the loss mse function instead of the loss function binary_crossentropy.\n",
    "* Try the tanh activation function (this function was popular at the beginning of the development of neural networks). Replace the relu function with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kG2DI2_t8vf"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "\n",
    "Here are the conclusions that can be drawn from this example:\n",
    "\n",
    "* Usually, data requires pre-treatment. After that operation, it can be routed in the form of tensors to the input of a neural network. The word sequence can be represented as vectors of binary values, but there are other ways to go about it.\n",
    "* Dense layer stacks with relu activation can be used to solve a variety of problems (including the tone classification). Consequently, you will most likely use them frequently in the future.\n",
    "* For the binary classification problem (two output classes) there should be a Dense layer with one unit and sigmoid activation function at the end of the network. The output values ​​generated by the network should be scalars in the range of 0 to 1 (it should be a probability).\n",
    "* In this configuration of the network output layer, the loss function should be the binary_crossentropy.\n",
    "* The rmsprop optimizer is generally a good choice for any problem. Consequently, you have one less thing to analyze.\n",
    "* Neural networks, as they learn more about the training data, start to over-adjust. This leads to a deterioration of the results of new data processing. You must constantly monitor network performance while processing data that is not part of the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.4_INT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3429981c687d110c4c5c63635eed955f89f79b5c29f7b8819e5bb3afec2d8ca0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
